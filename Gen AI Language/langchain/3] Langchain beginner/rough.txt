### LANGCHAIN CHAIN:

# LCEL = Langchain Expression Language (LCEL)
chain = prompt | model
prompt will pass to the model

# Chain Possibilities
chain1 -> Chain2 -> Chain3 -> .....-> Final chain

or have branch from one chain and  chain in parallel and meet in Final Chain

or have branching from one chain to multiple Final Chains


### CHAIN UNDER THE HOOD:
the core of langchain chain is RunnableLambda.
All the RunableLambda s are make chain in RunnableSequence


### PARALLEL CHAINS:

                            -> analyze 1 -> generate 1 -> content 1 ->
prompt -> model -> parser --                                        ->final
                            -> analyze 2 -> generate 2 -> content 2 => 


### Branches

chain with if else like conditional branch where only one chain will run from the multiple chains according to the conditional.

### Retrieval Augmented Generation
LLMs are constrained on how much knowledge they have
They cant answer the question that is currently new
So the main idea is to give information (context) so that it can answer it

document -> split -> Embed -> similarity search -> context -> LLMs -> Generate Response

document (10M tokens) -> chunks (1k tokens each) -> Embedding each chunk -> Store Embedding in Vector store

### RAG with MetaData
to reduce hallucinate i.e provide source along with the context to the model.